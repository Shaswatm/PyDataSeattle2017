{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bqplot import *\n",
    "from bqplot.marks import Graph\n",
    "from ipywidgets import IntSlider, Dropdown, RadioButtons, HBox, VBox, Button, Layout\n",
    "from bqplot import pyplot as plt\n",
    "from bqplot import OrdinalScale\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(0)\n",
    "data_df_total = pd.read_csv('./Data/credit-training.csv', index_col=0)\n",
    "result_column = 'SeriousDlqin2yrs'\n",
    "\n",
    "train_idx, test_idx = train_test_split(data_df_total.index.values, test_size=0.3,\n",
    "                                       stratify=data_df_total[result_column])\n",
    "train_data = data_df_total.loc[train_idx]\n",
    "test_data = data_df_total.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility functions for cleaning the data and adding features.\n",
    "\n",
    "overdue_cols = ['NumberOfTime30-59DaysPastDueNotWorse', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfTimes90DaysLate']\n",
    "rev_lines_col = 'RevolvingUtilizationOfUnsecuredLines'\n",
    "\n",
    "def clean_train_data(train_df):\n",
    "    train_df = train_df.copy()\n",
    "    \n",
    "    data_median = train_df.median()\n",
    "    fill_values = {}\n",
    "    fill_values['MonthlyIncome'] = data_median['MonthlyIncome']\n",
    "    \n",
    "    for col in overdue_cols:\n",
    "        num_overdue_df = train_df.loc[train_df[col] >= 90]            \n",
    "        fill_values[col] = train_df[col].median()\n",
    "        train_df.loc[num_overdue_df.index, col] = train_df[col].median()\n",
    " \n",
    "    ## filling the value for revolving unsecured lines.\n",
    "    rev_filtered_df = train_df[train_df[rev_lines_col] >= 4.0]\n",
    "    train_df.loc[rev_filtered_df.index, rev_lines_col] = train_df[rev_lines_col].median()\n",
    "    fill_values[rev_lines_col] = train_df[rev_lines_col].median()\n",
    "    return train_df, fill_values \n",
    "\n",
    "\n",
    "def clean_test_data(test_df, fill_values, fill_values_other):\n",
    "    test_df = test_df.copy()\n",
    "\n",
    "    for c in overdue_cols:\n",
    "        fill_idxs = test_df.index[test_df[c] >= 90]\n",
    "        test_df.loc[fill_idxs, c] = fill_values[c]\n",
    "\n",
    "    fill_rev_idxs = test_df.index[test_df[rev_lines_col] >= 4.0]\n",
    "    test_df.loc[fill_rev_idxs, rev_lines_col] = fill_values[rev_lines_col]\n",
    "    test_df = test_df.fillna(fill_values_other)\n",
    "    return test_df\n",
    "\n",
    "def add_features(data_frame):\n",
    "    return_dataframe = data_frame.copy()\n",
    "    return_dataframe[rev_lines_col+'ind'] = return_dataframe[rev_lines_col] == 0.\n",
    "    return_dataframe['overdue_ind'] = (return_dataframe[overdue_cols].sum(axis=1) == 0)\n",
    "    return return_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Data cleaning and adding additional features.\n",
    "data_median = train_data.median()\n",
    "train_data_clean, fill_dict = clean_train_data(train_data)\n",
    "data_median = train_data_clean.median()\n",
    "\n",
    "## fill in the remaining values with the median\n",
    "train_data_clean = train_data_clean.fillna(data_median)\n",
    "train_data_clean = add_features(train_data_clean)\n",
    "\n",
    "test_data_cleaned = clean_test_data(test_data, fill_dict, data_median)\n",
    "test_data_cleaned = add_features(test_data_cleaned)\n",
    "\n",
    "X_train = train_data_clean.drop(result_column, axis=1)\n",
    "y_train = train_data_clean[result_column]\n",
    "\n",
    "X_test = test_data_cleaned.drop(result_column, axis=1)\n",
    "y_test = test_data_cleaned[result_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "## Utility functions for model evaluation.\n",
    "def eval_preds(y_true, y_probs, y_preds):\n",
    "    return {'precision': precision_score(y_true, y_preds),\n",
    "            'accuracy': accuracy_score(y_true, y_preds),\n",
    "            'recall': recall_score(y_true, y_preds),\n",
    "            'auc': roc_auc_score(y_true, y_probs)}\n",
    "\n",
    "def get_model_eval(true_train, train_predictions, true_test=None, test_predictions=None):\n",
    "    train_eval = eval_preds(true_train, *train_predictions)\n",
    "    if true_test is None:\n",
    "        return pd.Series(train_eval)\n",
    "    else:\n",
    "        test_eval = eval_preds(true_test, *test_predictions)\n",
    "        return pd.DataFrame([train_eval, test_eval], index=['Train', 'Test'])\n",
    "\n",
    "def probas_to_classes(probas):\n",
    "    return (probas >= 0.5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training the model.\n",
    "num_epochs = 15\n",
    "batch_size = 5000\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "K.set_session(sess)\n",
    "\n",
    "sample_weights = np.ones(X_train.shape[0])\n",
    "\n",
    "## callback to compute the gradients\n",
    "class WeightsGradientsCallback(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.gradients = []\n",
    "        self.train_auc = []\n",
    "        self.test_auc = []\n",
    "        self.weights = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        input_values = [X_train_norm, sample_weights, y_train.values.reshape(-1, 1), 0]\n",
    "        gradient_values = compute_gradients(input_values)\n",
    "        self.gradients.append(gradient_values)\n",
    "        \n",
    "        self.train_auc.append(roc_auc_score(y_train.values.flatten(), \n",
    "                                            self.model.predict(X_train_norm)))\n",
    "        self.test_auc.append(roc_auc_score(y_test.values.flatten(), \n",
    "                                           self.model.predict(X_test_norm)))\n",
    "        \n",
    "        auc_line.x = np.arange(0, epoch + 1)\n",
    "        auc_line.y = [self.train_auc, self.test_auc]\n",
    "        \n",
    "        weights = list(range(len(self.model.layers)))\n",
    "        for i, l in enumerate(self.model.layers):\n",
    "            weights[i] = l.get_weights()\n",
    "        self.weights.append(weights)\n",
    "\n",
    "test_call_back = WeightsGradientsCallback()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_norm = scaler.fit_transform(X_train.values)\n",
    "X_test_norm = scaler.transform(X_test.values)\n",
    "dropout_prob = 0.15\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=X_train_norm.shape[1], activation='relu'))\n",
    "model.add(Dropout(dropout_prob))\n",
    "\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "gradients = model.optimizer.get_gradients(model.model.total_loss, \n",
    "                                          model.trainable_weights)\n",
    "input_tensors = [model.model.inputs[0], model.model.sample_weights[0], \n",
    "                 model.model.targets[0], K.learning_phase()]\n",
    "compute_gradients = K.function(inputs=input_tensors, outputs=gradients)   \n",
    "\n",
    "\n",
    "auc_fig = plt.figure(title='Train and Test AUC vs epoch', legend_location='top-left')\n",
    "auc_line = plt.plot([0], [0], marker='circle', marker_size=32, colors=['DeepSkyBlue', 'Red'], \n",
    "                              labels=['Training', 'Test'], display_legend=True)\n",
    "display(auc_fig)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_norm, y_train.values, verbose=2,\n",
    "          epochs=num_epochs, batch_size=batch_size,\n",
    "           callbacks=[test_call_back])\n",
    "\n",
    "train_probs = model.predict(X_train_norm).flatten()\n",
    "train_preds = probas_to_classes(train_probs)\n",
    "\n",
    "test_probs = model.predict(X_test_norm).flatten()\n",
    "test_preds = probas_to_classes(test_probs)\n",
    "\n",
    "\n",
    "model_eval = get_model_eval(y_train, [train_probs, train_preds],\n",
    "                            y_test, [test_probs, test_preds])\n",
    "print(model_eval)\n",
    "sess.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cleaned_weights(weights_mat):\n",
    "    weights_ret = []\n",
    "    for w in weights_mat:\n",
    "        if np.shape(w)[0] == 0:\n",
    "            # this is a dropout layer or a reg layer which does no have weights\n",
    "            pass\n",
    "        else:\n",
    "            weights_ret.append(w)\n",
    "    return weights_ret\n",
    "\n",
    "def get_weights_for_node_at_layer(weights, epoch_num, layer_num, node_num):\n",
    "    # max_layers = len(weights)\n",
    "    layer_params = weights[epoch_num][layer_num]\n",
    "    \n",
    "    layer_weights = layer_params[0]\n",
    "    layer_bias = layer_params[1]\n",
    "    \n",
    "    node_weights = layer_weights[:, node_num]\n",
    "    node_bias = layer_bias[node_num]\n",
    "    \n",
    "    return (node_bias, node_weights)\n",
    "\n",
    "def get_gradients_for_node_at_layer(gradients, epoch_num, layer_num, node_num):\n",
    "    layer_gradients = gradients[epoch_num][2 * layer_num]\n",
    "    layer_bias_gradients = gradients[epoch_num][2 * layer_num + 1]\n",
    "    \n",
    "    node_gradients = layer_gradients[:, node_num]\n",
    "    node_bias_gradiens = layer_bias_gradients[node_num]\n",
    "    \n",
    "    return(node_bias_gradiens, node_gradients)\n",
    "\n",
    "cleaned_weights = []\n",
    "\n",
    "for w in test_call_back.weights:\n",
    "    cleaned_weights.append(get_cleaned_weights(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain, product\n",
    "class NeuralNet(Figure):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.height = kwargs.get('height', 800)\n",
    "        self.width = kwargs.get('width', 900)\n",
    "        self.directed_links = kwargs.get('directed_links', False)\n",
    "        \n",
    "        self.num_inputs = kwargs['num_inputs']\n",
    "        self.num_hidden_layers = kwargs['num_hidden_layers']\n",
    "        self.nodes_output_layer = kwargs['num_outputs']\n",
    "        self.layer_colors = kwargs.get('layer_colors', \n",
    "                                       ['Orange'] * (len(self.num_hidden_layers) + 2))\n",
    "        \n",
    "        self.build_net()\n",
    "        super(NeuralNet, self).__init__(**kwargs)\n",
    "    \n",
    "    def build_net(self):\n",
    "        # create nodes\n",
    "        self.layer_nodes = []\n",
    "        self.layer_nodes.append(['x' + str(i+1) for i in range(self.num_inputs)])\n",
    "        \n",
    "        for i, h in enumerate(self.num_hidden_layers):\n",
    "            self.layer_nodes.append(['h' + str(i+1) + ',' + str(j+1) for j in range(h)])\n",
    "        self.layer_nodes.append(['y' + str(i+1) for i in range(self.nodes_output_layer)])\n",
    "        \n",
    "        self.flattened_layer_nodes = list(chain(*self.layer_nodes))\n",
    "        \n",
    "        # build link matrix\n",
    "        i = 0\n",
    "        node_indices = {}\n",
    "        for layer in self.layer_nodes:\n",
    "            for node in layer:\n",
    "                node_indices[node] = i\n",
    "                i += 1\n",
    "\n",
    "        n = len(self.flattened_layer_nodes)\n",
    "        self.link_matrix = np.empty((n,n))\n",
    "        self.link_matrix[:] = np.nan\n",
    "\n",
    "        for i in range(len(self.layer_nodes) - 1):\n",
    "            curr_layer_nodes_indices = [node_indices[d] for d in self.layer_nodes[i]]\n",
    "            next_layer_nodes = [node_indices[d] for d in self.layer_nodes[i+1]]\n",
    "            for s, t in product(curr_layer_nodes_indices, next_layer_nodes):\n",
    "                self.link_matrix[s, t] = 1\n",
    "        \n",
    "        # set node x locations\n",
    "        self.nodes_x = np.repeat(np.linspace(0, 100, \n",
    "                                             len(self.layer_nodes) + 1, \n",
    "                                             endpoint=False)[1:], \n",
    "                                 [len(n) for n in self.layer_nodes])\n",
    "\n",
    "        # set node y locations\n",
    "        self.nodes_y = np.array([])\n",
    "        for layer in self.layer_nodes:\n",
    "            n = len(layer)\n",
    "            ys = np.linspace(0, 100, n+1, endpoint=False)[1:]\n",
    "            self.nodes_y = np.append(self.nodes_y, ys[::-1])\n",
    "        \n",
    "        # set node colors\n",
    "        n_layers = len(self.layer_nodes)\n",
    "        self.node_colors = np.repeat(np.array(self.layer_colors[:n_layers]), \n",
    "                                     [len(layer) for layer in self.layer_nodes]).tolist()\n",
    "        \n",
    "        xs = LinearScale(min=0, max=100)\n",
    "        ys = LinearScale(min=0, max=100)\n",
    "        \n",
    "        self.graph = Graph(node_data=[{'label': d, \n",
    "                                       'label_display': 'none'} for d in self.flattened_layer_nodes], \n",
    "                           link_matrix=self.link_matrix, link_type='line',\n",
    "                           colors=self.node_colors, directed=self.directed_links,\n",
    "                           scales={'x': xs, 'y': ys}, x=self.nodes_x, y=self.nodes_y)\n",
    "        self.graph.hovered_style = {'stroke': '1.5'}\n",
    "        self.graph.unhovered_style = {'opacity': '0.4'}\n",
    "        self.graph.selected_style = {'opacity': '1',\n",
    "                                     'stroke': 'red',\n",
    "                                     'stroke-width': '2.5'}\n",
    "        self.marks = [self.graph]\n",
    "        self.title = 'Analyzing the Trained Neural Network'\n",
    "        self.layout.width = str(self.width) + 'px'\n",
    "        self.layout.height = str(self.height) + 'px'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = NeuralNet(num_inputs=12, num_hidden_layers=[20, 10], num_outputs=1)\n",
    "\n",
    "epoch_slider = IntSlider(description='Epoch:', min=1, max=num_epochs, value=1)\n",
    "mode_dd = Dropdown(description='View', options=['Weights', 'Gradients'], value='Weights')\n",
    "agg_radio = RadioButtons(description='Aggregation', options=['Nodes', 'Layers'], value='Nodes')\n",
    "update_btn = Button(description='Update')\n",
    "\n",
    "bar_figure = plt.figure()\n",
    "bar_plot = plt.bar([], [], scales={'x': OrdinalScale()})\n",
    "\n",
    "controls = HBox([epoch_slider, mode_dd, agg_radio, update_btn])\n",
    "nn.graph.tooltip = bar_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def update_bar_chart(layer, node):\n",
    "    epoch = epoch_slider.value\n",
    "    \n",
    "    if mode_dd.value == 'Weights':\n",
    "        display_vals = get_weights_for_node_at_layer(cleaned_weights, epoch, layer-1, node)\n",
    "    else:\n",
    "        display_vals = get_gradients_for_node_at_layer(test_call_back.gradients, epoch, layer-1, node)\n",
    "    return_vals = np.append([display_vals[0]], display_vals[1])\n",
    "    \n",
    "    bar_figure.title = mode_dd.value + ' for layer:' + str(layer) + ' node: ' + str(node) + ' at epoch: ' + str(epoch)\n",
    "    bar_plot.x = np.arange(len(return_vals))\n",
    "    bar_plot.y = return_vals\n",
    "    \n",
    "node_counts = [nn.num_inputs] + nn.num_hidden_layers + [nn.nodes_output_layer]\n",
    "\n",
    "def hovered_change(change):\n",
    "    point_index = change['new']\n",
    "    if point_index is None:\n",
    "        return\n",
    "    else:\n",
    "        for i, n in enumerate(node_counts):\n",
    "            if point_index < n:\n",
    "                break\n",
    "            else:\n",
    "                point_index = point_index - n\n",
    "        if i > 0:\n",
    "            update_bar_chart(i, point_index)\n",
    "    \n",
    "nn.graph.observe(hovered_change, 'hovered_point')\n",
    "\n",
    "VBox([controls, nn], layout=Layout(min_height='1000px'))    "
   ]
  }
 ],
 "metadata": {
  "input_collapsed": false,
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
